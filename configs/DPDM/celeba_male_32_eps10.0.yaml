setup:
  method: dpsgd-diffusion
  run_type: torchmp
  n_gpus_per_node: 3
  n_nodes: 1
  node_rank: 0
  master_address: 127.0.0.1
  master_port: 6025
  omp_n_threads: 8
  workdir: null
public_data:
  name: null
  num_channels: 3
  resolution: 32
  n_classes: 1000
  train_path: dataset/imagenet/imagenet_32
  selective:
    ratio: 1.0
sensitive_data:
  name: celeba_male_32
  num_channels: 3
  resolution: 32
  n_classes: 2
  train_path: dataset/celeba/train_32_Male.zip
  test_path: dataset/celeba/test_32_Male.zip
  fid_stats: dataset/celeba/fid_stats_32.npz
model:
  ckpt: null
  denoiser_name: edm
  denoiser_network: song
  ema_rate: 0.999
  network:
    image_size: 32
    num_in_channels: 3
    num_out_channels: 3
    label_dim: 1000
    attn_resolutions:
    - 16
    ch_mult:
    - 2
    - 4
  sampler:
    type: ddim
    stochastic: false
    num_steps: 50
    tmin: 0.002
    tmax: 80.0
    rho: 7.0
    guid_scale: 0.0
    snapshot_batch_size: 80
    fid_batch_size: 256
  sampler_fid:
    type: ddim
    stochastic: false
    num_steps: 250
    tmin: 0.002
    tmax: 80.0
    rho: 7.0
    guid_scale: 0.0
  sampler_acc:
    type: ddim
    stochastic: false
    num_steps: 250
    tmin: 0.002
    tmax: 80.0
    rho: 7.0
    guid_scale: 0.0
  private_num_classes: 2
  public_num_classes: 1000
pretrain:
  log_dir: null
  seed: 0
  batch_size: 1024
  n_epochs: 160
  log_freq: 100
  snapshot_freq: 2000
  snapshot_threshold: 1
  save_freq: 100000
  save_threshold: 1
  fid_freq: 2000
  fid_samples: 5000
  fid_threshold: 1
  optim:
    optimizer: Adam
    params:
      lr: 3e-4
      weight_decay: 0.0
  loss:
    version: edm
    p_mean: -1.2
    p_std: 1.2
    n_noise_samples: 1
    n_classes: 1000
  cond: true
train:
  log_dir: null
  seed: 0
  batch_size: 4096
  n_epochs: 150
  partly_finetune: false
  log_freq: 100
  snapshot_freq: 2000
  snapshot_threshold: 1
  save_freq: 100000
  save_threshold: 1
  fid_freq: 2000
  fid_samples: 5000
  final_fid_samples: 60000
  fid_threshold: 1
  gen: false
  gen_batch_size: 8192
  optim:
    optimizer: Adam
    params:
      lr: 3e-4
      weight_decay: 0.0
  loss:
    version: edm
    p_mean: -1.2
    p_std: 1.2
    n_noise_samples: 32
    n_classes: 2
  dp:
    max_grad_norm: 0.001
    delta: 1e-6
    epsilon: 10.0
    max_physical_batch_size: 8192
    privacy_history: null
  n_splits: 64
gen:
  data_num: 60000
  batch_size: 1000
  log_dir: null
eval:
  batch_size: 1000
  mode: val
