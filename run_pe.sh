export HF_HOME='/bigtemp/fzv6en/diffuser_cache'

# python run.py setup.n_gpus_per_node=3 model.api=stable_diffusion model.api_params.random_sampling_checkpoint=stable-diffusion-v1-5/stable-diffusion-v1-5  model.api_params.variation_checkpoint=stable-diffusion-v1-5/stable-diffusion-v1-5 train.variation_degree_schedule=[1.0,1.0,1.0,0.75,0.75,0.75,0.75,0.5,0.5,0.5,0.5] model.api_params.random_sampling_num_inference_steps=10 model.api_params.variation_num_inference_steps=10 model.api_params.random_sampling_batch_size=30 model.api_params.variation_batch_size=30 train.image_size=512x512 -m PE -dn mnist_28 -e 10.0

# python run.py setup.n_gpus_per_node=3 model.api=stable_diffusion model.api_params.random_sampling_checkpoint=stable-diffusion-v1-5/stable-diffusion-v1-5  model.api_params.variation_checkpoint=stable-diffusion-v1-5/stable-diffusion-v1-5 train.variation_degree_schedule=[1.0,0.9,0.8,0.7,0.6,0.5] train.num_samples_schedule=[36000,36000,36000,36000,36000,36000] model.api_params.random_sampling_batch_size=30 model.api_params.variation_batch_size=30 train.image_size=512x512 -m PE -dn cifar10_32 -e 10.0 -ed numsample36k_10steps train.combine_variation_extraction=true model.api_params.random_sampling_num_inference_steps=10 model.api_params.variation_num_inference_steps=10

# python run.py setup.n_gpus_per_node=3 model.api=stable_diffusion model.api_params.random_sampling_checkpoint=stable-diffusion-v1-5/stable-diffusion-v1-5  model.api_params.variation_checkpoint=stable-diffusion-v1-5/stable-diffusion-v1-5 train.variation_degree_schedule=[1.0,0.95,0.9,0.85,0.8,0.75] model.api_params.random_sampling_num_inference_steps=10 model.api_params.variation_num_inference_steps=10 model.api_params.random_sampling_batch_size=30 model.api_params.variation_batch_size=30 train.image_size=512x512 -m PE -dn cifar10_32 -e 10.0 -ed large_var_10steps train.combine_variation_extraction=true

python run.py setup.n_gpus_per_node=3 model.api=stable_diffusion model.api_params.random_sampling_checkpoint=stable-diffusion-v1-5/stable-diffusion-v1-5  model.api_params.variation_checkpoint=stable-diffusion-v1-5/stable-diffusion-v1-5 train.variation_degree_schedule=[1.0,1.0,1.0,0.75,0.75,0.75,0.75,0.5,0.5,0.5,0.5] train.num_samples_schedule=[24000,24000,24000,24000,24000,24000] model.api_params.random_sampling_batch_size=30 model.api_params.variation_batch_size=30 train.image_size=512x512 -m PE -dn octmnist_128 -e 10.0 -ed numsample24k_10steps train.combine_variation_extraction=true model.api_params.random_sampling_num_inference_steps=10 model.api_params.variation_num_inference_steps=10

# python run.py setup.n_gpus_per_node=3 model.api=stable_diffusion model.api_params.random_sampling_checkpoint=stable-diffusion-v1-5/stable-diffusion-v1-5  model.api_params.variation_checkpoint=stable-diffusion-v1-5/stable-diffusion-v1-5 train.variation_degree_schedule=[1.0,0.95,0.9,0.85,0.8,0.75] model.api_params.random_sampling_batch_size=30 model.api_params.variation_batch_size=30 train.image_size=512x512 -m PE -dn celeba_male_256 -e 10.0 -ed numsample24k_10steps train.combine_variation_extraction=true model.api_params.random_sampling_num_inference_steps=10 model.api_params.variation_num_inference_steps=10

# python run.py setup.n_gpus_per_node=3 model.api=stable_diffusion model.api_params.random_sampling_checkpoint=stable-diffusion-v1-5/stable-diffusion-v1-5  model.api_params.variation_checkpoint=stable-diffusion-v1-5/stable-diffusion-v1-5 train.variation_degree_schedule=[1.0,1.0,1.0,1.0,1.0,0.75,0.75,0.75] model.api_params.random_sampling_num_inference_steps=10 model.api_params.variation_num_inference_steps=10 model.api_params.random_sampling_batch_size=30 model.api_params.variation_batch_size=30 train.image_size=512x512 -m PE -dn camelyon_96 -e 10.0 -ed numsample24k_10steps train.combine_variation_extraction=true model.api_params.random_sampling_num_inference_steps=10 model.api_params.variation_num_inference_steps=10